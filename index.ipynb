{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect Size, P-Values and Power - Lab\n",
    "\n",
    "## Introduction \n",
    "\n",
    "In this lab, you'll run simulations to continue to investigate the relationship between effect size, p-values, power and sample size!\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "* Describe how effect size, sample size and p_value are related to each other. \n",
    "* Use Welch's t-test for distributions that do not have a normality assumption.\n",
    "* Plot visualisations to confirm the calculations and intuitions towards p_value and effect size. \n",
    "* Explain how with a same effect size, we may see different p_values with increasing number of simulations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Philosophical Review\n",
    "\n",
    "Remember that the underlying question behind all hypothesis tests is:\n",
    "\n",
    ">\"What is the probability I would see this effect due to random fluctuations if there was actually no effect?\" \n",
    "\n",
    "This is exactly what a p-value represents: the chance that the observed data would satisfy the null hypothesis. As such, if the p-value is sufficiently low, you can declare the results statistically significant and reject the null hypothesis. Recall that this threshold is defined as $\\alpha$, and is also the rate of type I errors. In this lab, you'll investigate the robustness of p-values and their relation with effect-size and sample-size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Starter Functions\n",
    "\n",
    "To start, import the functions stored in the `flatiron_stats.py` file. It contains the stats functions that you previously coded in the last lab: `welch_t(a,b)`, `welch_df(a, b)` and `p_value(a, b, two_sided=False)`. You'll then use these functions below to further investigate the relationship between p-values and sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTRIBUTING.md  images  index.ipynb  LICENSE.md  README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def welch_df(a, b):\n",
    "    num = ((np.std(a)/len(a)) + (np.std(b)/len(b)))**2\n",
    "    den = np.std(a)**2/(len(a)**2 * (len(a)-1) )+ (np.std(b)**2/(len(b)**2 *(len(b)-1)) )\n",
    "    \n",
    "    \"\"\" Calculate the effective degrees of freedom for two samples. \"\"\"\n",
    "    return num/den\n",
    "\n",
    "\n",
    "def welch_t(a, b):\n",
    "    \"\"\" Calculate Welch's t statistic for two samples. \"\"\"\n",
    "    m1 = np.mean(a)\n",
    "    m2 = np.mean(b)\n",
    "    num = m2-m1\n",
    "    \n",
    "    den = ((np.std(a)/len(a)) + (np.std(b)/len(b)))**.5\n",
    "    \n",
    "    \n",
    "    return num/den\n",
    "\n",
    "def p_value(a, b, two_sided=False):\n",
    "    p = stats.t.cdf(welch_t(a,b), welch_df(a,b))\n",
    "    if two_sided: p = 2* p\n",
    "    return p #Return the p-value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Random Samples\n",
    "\n",
    "Before you start running simulations, it will be useful to have a helper function that will generate random samples. Write such a function below which generates 2 random samples from 2 normal distributions. The function should take 6 input parameters:\n",
    "\n",
    "* m1 - The underlying population mean for sample 1\n",
    "* s1 - The underlying population standard deviation for sample 1\n",
    "* n1 - The sample size for sample 1\n",
    "\n",
    "* m2 - The underlying population mean for sample 2\n",
    "* s2 - The underlying population standard deviation for sample 2\n",
    "* n2 - The sample size for sample 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_samples(m1,s1,n1,m2,s2,n2):\n",
    "    #Your code here; have the function create two random samples using the input parameters\n",
    "    sample1 = np.random.normal(loc=m1,scale=s1, size=n1)\n",
    "    sample2 = np.random.normal(loc=m2,scale=s2, size=n2)\n",
    "    return sample1, sample2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a Simulation\n",
    "\n",
    "For your first simulation, you're going to investigate how the p-value of an experiment relates to sample size when both samples are from identical underlying distributions. To do this, use your `generate_samples()` function along with the `p_value_welch_ttest()` function defined in the flatiron_stats file. Use sample sizes from 5 to 750. For each sample size, simulate 100 experiments. For each of these experiments, generate 2 samples of the given sample size, each with a mean of 5 and a standard deviation of 1. Calculate the corresponding p-values for a Welch's t-test for each of these sample-pairs. Finally, use the p-values to calculate the power of the test. Remember that for all of the simulations where the effect size does not equal zero, the null hypothesis is not true. Store the overall power from the 100 simulations along with the corresponding sample size and effect size. Repeat this for varying effect sizes such as [0, 0.01,.1,.2, .5, 1, 2]. Afterwards, you'll then plot power vs sample size for various effect sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "effects = [0, 0.01,.1,.2, .5, 1, 2]\n",
    "\n",
    "output = []\n",
    "\n",
    "for effect in effects:\n",
    "    for size in range(5,750):\n",
    "        pvals = []\n",
    "        for i in range(100):\n",
    "            sample1, sample2 = generate_samples(5,1,size,5 + effect,1,size)\n",
    "            pvals.append(p_value(sample1, sample2))\n",
    "        power = sum([1 for x in pvals if x<effect])/size\n",
    "        output.append([effect, size, power])\n",
    "        \n",
    "import pandas as pd\n",
    "power = pd.DataFrame(output)\n",
    "\n",
    "# for effect size:\n",
    "#     for sample_size:\n",
    "#         perform 100 simulations\n",
    "#         calculate power\n",
    "#         store effect_size, sample_size, power for simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've simulated the data, go ahead and graph it! Label the x-axis sample size, the y-axis power, and be sure to include a legend for the various effect sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for effect in effects[0:1]:\n",
    "    temp = power[power[2] == effect]\n",
    "    plt.scatter(temp[1], temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    74500.000000\n",
       "mean         0.498809\n",
       "std          0.289159\n",
       "min          0.000024\n",
       "25%          0.247871\n",
       "50%          0.496809\n",
       "75%          0.750903\n",
       "max          0.999999\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it's also typically incredibly difficult (if not impossible) to accuractely detect effect sizes below .1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This lesson summarizes and further builds upon the ideas that we saw in the previous labs. We learnt how p_value can be described as a function of effect size and for a given effect size, the p_value may get lower if we increase the sample size considerably. We also saw how p_value alone can not be used in order to identify some results as truly siginifcant, as this can be achieved when there is not a significant effect size. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
